<html>

<head>
    <meta charset="utf-8" />
    <title>Pri4R: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation</title>

    <!-- Favicon references -->
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    <link rel="icon" type="image/jpeg" href="favicon.jpg">
    <link rel="apple-touch-icon" href="favicon.jpg">

    <meta
        content="Pri4R: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation"
        name="description" />
    <meta
        content="Pri4R: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation"
        property="og:title" />
    <meta
        content="Pri4R: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation"
        property="og:description" />
    <meta content="https://describe-anything.github.io/images/slideshow/slide1_full.jpg" property="og:image" />
    <meta
        content="Pri4R: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation"
        property="twitter:title" />
    <meta
        content="Pri4R: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation"
        property="twitter:description" />
    <meta content="https://describe-anything.github.io/images/slideshow/slide1_full.jpg" property="twitter:image" />
    <meta property="og:type" content="website" />
    <meta content="summary_large_image" name="twitter:card" />
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"
        crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&family=Varela+Round&display=swap"
        rel="stylesheet">
    <link href="style.css" rel="stylesheet" type="text/css" />
</head>

<body>
    <header class="site-header">
        <div class="container">
            <nav class="main-nav">
                <ul class="nav-links">
                    <li><a href="#abstract">Overview</a></li>
                    <li><a href="#pipeline">Pipeline</a></li>
                    <li><a href="#data-pipeline">Data</a></li>
                    <li><a href="#dlc-bench">Benchmark</a></li>
                    <li><a href="#citation">Citation</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <div class="hero-section">
        <div class="container">
            <div class="title-row">
                <h1 class="title"><span class="gradient-text">Pri4R</span>: Learning World Dynamics for Vision-Language-Action Models with Privileged 4D Representation</h1>
                <h1 class="subtitle">Arxiv 2026</h1>
            </div>
            <div class="base-row author-row">
                <div class="base-col author-col">
                    <a href="https://jiiiisoo.github.io/" target="_blank" class="author-text">
                        Jisoo Kim<sup>*1,2</sup>
                    </a>
                </div>
                <div class="base-col author-col">
                    <a href="https://whwjdqls.github.io/" target="_blank" class="author-text">
                        Jungbin Cho<sup>*3,5</sup>
                    </a>
                </div>
                <div class="base-col author-col">
                    <a href="https://sanghyeokchu.github.io/" target="_blank" class="author-text">
                        Sanghyeok Chu<sup>2,4</sup>
                    </a>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Ananya Bal<sup>5</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Jinhyung Kim<sup>2</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Gunhee Lee<sup>2</sup></span>
                </div>
            </div>
            <div class="base-row author-row">
                <div class="base-col author-col">
                    <span class="author-text">Sihaeng Lee<sup>2</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Seung Hwan Kim<sup>2</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Bohyung Han<sup>&dagger;4</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Hyunmin Lee<sup>&dagger;2</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Laszlo A. Jeni<sup>&dagger;5</sup></span>
                </div>
                <div class="base-col author-col">
                    <span class="author-text">Seungryong Kim<sup>&dagger;1</sup></span>
                </div>
            </div>
            <div class="base-row author-row">
                <div class="base-col author-col affiliations">
                    <sup>1</sup>KAIST AI &nbsp;&nbsp; <sup>2</sup>LG AI Research &nbsp;&nbsp; <sup>3</sup>Yonsei University &nbsp;&nbsp; <sup>4</sup>Seoul National University &nbsp;&nbsp; <sup>5</sup>Carnegie Mellon University
                </div>
            </div>
            <div class="link-labels base-row">
                <div class="base-col icon-col"><a href="https://arxiv.org/abs/2504.16072" target="_blank"
                        class="link-block">
                        <i class="fa fas fa-file-text main-icon"></i>
                        <strong class="link-labels-text">Paper</strong>
                    </a></div>
                <div class="base-col icon-col"><a href='#video'
                        class="link-block">
                        <i class="fa fa-video-camera main-icon"></i>
                        <strong class="link-labels-text">Video</strong>
                    </a></div>
                <!-- <div class="base-col icon-col"><a href='https://huggingface.co/spaces/nvidia/describe-anything-model-demo'
                        class="link-block">
                        <i class="fa fa-cube main-icon"></i>
                        <strong class="link-labels-text">Interactive Demo</strong>
                    </a></div> -->
                <div class="base-col icon-col"><a href='https://github.com/NVlabs/describe-anything' class="link-block">
                        <i class="fa fa-github main-icon"></i>
                        <strong class="link-labels-text">Code (Coming Soon)</strong>
                    </a></div>
                <div class="base-col icon-col"><a href="https://huggingface.co/collections/nvidia/describe-anything-680825bb8f5e41ff0785834c"
                        class="link-block">
                        <i class="fa fa-database main-icon"></i>
                        <strong class="link-labels-text">Models/Data (Coming Soon)</strong>
                    </a></div>
                <div class="base-col icon-col"><a href="#citation" class="link-block">
                        <i class="fa fa-graduation-cap main-icon"></i>
                        <strong class="link-labels-text">Citation</strong>
                    </a></div>
            </div>

        </div>
    </div>

    <main class="main-content">
        <div class="container">
            <div class="tldr">
                <b>TL;DR</b>: Pri4R improves VLAâ€™s physical interaction capabilities by leveraging privileged 4D supervision to instill an implicit understanding of world dynamics, incurring no inference overhead and yielding large gains on manipulation tasks.
            </div>

            <section id="additional-examples" class="section" style="margin: -1rem 0 -2rem 0;">
                <div class="slideshow-container">
                    <div class="slideshow">
                        <div class="slide">
                            <img src="images/examples/1.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A medium-sized dog with a thick, reddish-brown coat and a white underbelly and legs. The dog has a bushy tail, pointed ears, and a red collar with a silver tag. Its mouth is open, showing its teeth, and its tongue is hanging out. The dog is in a running pose with its front legs extended forward and its back legs stretched out behind.
                            </div>
                        </div>
                        <div class="slide">
                            <video src="images/examples/8.mp4" class="slideshow-image-video" autoplay muted loop></video>
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A vibrant goldfish with a striking pattern of orange and black spots glides gracefully through the water.
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/examples/2.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A blue wooden chair with a straight backrest featuring three vertical slats. The seat is flat and rectangular, and the chair has four sturdy legs.
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/examples/3.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A round, green metal table with a flat, circular top. The table has a cylindrical base with a horizontal black band around its middle. The base is supported by four black metal legs.
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/examples/4.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> The balcony features an ornate wrought iron railing with intricate floral and geometric patterns.
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/examples/5.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A white cat with light orange ears and a pink nose. The cat has a relaxed expression with slightly closed eyes and a soft, white fur coat.
                            </div>
                        </div>
                        <div class="slide">
                            <video src="images/examples/9.mp4" class="slideshow-image-video" autoplay muted loop></video>
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A monkey with a light brown coat and a slightly darker face is seen in a series of dynamic movements.
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/examples/6.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> The eye has a dark, almost black pupil surrounded by a thick, irregularly shaped iris.
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/examples/7.jpg" class="slideshow-image">
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A modern skyscraper with a sleek, rectangular design featuring a series of vertical, evenly spaced windows.
                            </div>
                        </div>
                        <div class="slide">
                            <video src="images/examples/10.mp4" class="slideshow-image-video" autoplay muted loop></video>
                            <div class="image-caption">
                                <b>Caption from DAM:</b> A cow with a rich brown coat and a lighter patch on its rump is depicted in a sequence of movements.
                            </div>
                        </div>
                    </div>

                    <button class="slideshow-nav prev" onclick="changeSlide(-1)">&#10094;</button>
                    <button class="slideshow-nav next" onclick="changeSlide(1)">&#10095;</button>

                    <div class="slideshow-controls">
                        <button class="play-pause" onclick="togglePlayPause()">
                            <i class="fa fa-pause"></i>
                        </button>
                    </div>
                </div>
            </section>

            <section id="abstract" class="section">
                <h2>Introducing the Pri4R</h2>

                <p> The Pri4R is a </p>
                <div class="image-container">
                    <img src="image/main_figure.jpg" class="img large-image">
                </div>
            </section>

            <!-- <div id="video" class="base-row">
                <div class="video-container main-video-container">
                    <video class="slideshow-video align-bottom main-video" controls poster="images/slideshow/slide1_full.jpg">
                        <source src="images/video.mov" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <div class="play-button-overlay">
                        <i class="fa fa-play"></i>
                    </div>
                </div>
            </div> -->

            <!-- <section id="task-definition" class="section">
                <h2>Detailed Localized Captioning (DLC)</h2>

                <p>Detailed Localized Captioning (DLC) is the task of generating comprehensive and context-aware descriptions of specific regions within an image. Unlike traditional image captioning, which summarizes the entire scene in broad strokes, DLC dives deeper into the finer details of a user-specified area.</p>
                <div class="image-container">
                    <div class="image-content">
                        <img src="images/slideshow/slide1.jpg" class="img large-image">
                    </div>
                    <p class="image-caption"><strong>Describe Anything Model (DAM)</strong> performs detailed localized captioning (DLC), generating <strong>detailed</strong> and <strong>localized</strong> descriptions for user-specified regions within <em>images</em>.<br/> <span class="image-credit">(Image credit: Markus Trienke (CC BY-SA 2.0))</span></p>
                </div>

                <p>DLC extends naturally to videos by describing how a specified region's appearance and context change over time.</p>
                <div class="image-container">
                    <video class="slideshow-video align-bottom" autoplay muted loop poster="images/slideshow/slide2.jpg">
                        <source src="images/video_example.mov" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="image-caption"><strong>Describe Anything Model (DAM)</strong> can also perform detailed localized video captioning.<br/> <span class="image-credit">(Video credit: MOSE Dataset (CC BY-NC-SA 4.0))</span></p>
                </div>
            </section>

            <section id="highly-detailed-captioning" class="section">
                <h2>Highly Detailed Image and Video Captioning</h2>

                <p>Our method excels at producing detailed descriptions of objects in both images and videos.</p>
                <div class="image-container">
                    <img src="images/slideshow/slide3.jpg"
                        class="image-item img large-image z-depth-1">
                    <p class="image-caption">Compared to prior works, the description from our <strong>Describe Anything Model (DAM)</strong> is more detailed and accurate. <span class="image-credit">(Image credit: SAM Materials (CC BY-SA 4.0))</span></p>
                </div>
            </section> -->

            <section id="pipeline" class="section">
                <h2>Pipeline of Pri4R</h2>

                <p>Pri4R is a framework that incorporates privileged geometric information to improve the world dynamics understanding of VLA models. 
                    During training, we use high-fidelity 4D signals as an auxiliary supervision to refine the internal representations of the VLM backbone. 
                    By supervising the model to predict the physical evolution of the scene, we enable the VLA to develop a physically-aware context for robot control, without requiring any additional inputs or computational overhead during inference.</p>
                <div class="image-container">
                    <img src="image/method.jpg"
                        class="image-item img large-image z-depth-1">
                    <p class="image-caption"><span class="image-credit">Image credit: Objects365 Dataset (CC BY 4.0)</span></p>
                </div>

                <!-- <p>We introduce a localized vision backbone that integrates global and focal features.</p>
                <div class="image-container" style="display: flex; justify-content: center;">
                    <img src="images/slideshow/slide7.jpg"
                        class="image-item img large-image z-depth-1" style="max-width: 500px; width: 50%;">
                </div> -->
            </section>

            <section id="data-pipeline" class="section">
                <h2>Semi-supervised Data Pipeline (DLC-SDP)</h2>

                <p>Because existing datasets lack detailed localized descriptions, we devised a two-stage pipeline.</p>
                <div class="image-container">
                    <img src="images/slideshow/slide8.jpg"
                        class="image-item img large-image z-depth-1">
                </div>
            </section>

            <section id="dlc-bench" class="section">
                <h2>DLC-Bench: A Benchmark for Detailed Localized Captioning</h2>

                <p>We introduce DLC-Bench, a benchmark that uses an LLM-based judge to evaluate a model's region-based descriptions.</p>
                <div class="image-container">
                    <img src="images/slideshow/slide9.jpg"
                        class="image-item img large-image z-depth-1">
                    <p class="image-caption">In DLC-Bench, a captioning model is prompted to describe a specified image region.<br/> <span class="image-credit">(Image credit: Objects365 Dataset (CC BY 4.0))</span></p>
                </div>
            </section>

            <section id="comparison" class="section">
                <h2>Comparison</h2>

                <p>On DLC-Bench, our model outperforms existing solutions by producing more detailed and accurate localized descriptions with less hallucination.</p>

                <div class="slideshow-container">
                    <div class="slideshow">
                        <div class="slide">
                            <img src="images/results/1.png" class="comparison-slideshow-image">
                            <div class="image-caption">
                                <b>Accuracies on detailed localized captioning in our proposed DLC-Bench.</b>
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/results/2.png" class="comparison-slideshow-image">
                            <div class="image-caption">
                                <b>Detailed localized video captioning on HC-STVG.</b>
                            </div>
                        </div>
                        <div class="slide">
                            <img src="images/results/3.png" class="comparison-slideshow-image">
                            <div class="image-caption">
                                <b>Performance on detailed localized video description on VideoRefer-Bench-D.</b>
                            </div>
                        </div>
                    </div>

                    <button class="slideshow-nav prev" onclick="changeSlide(-1)">&#10094;</button>
                    <button class="slideshow-nav next" onclick="changeSlide(1)">&#10095;</button>

                    <div class="slideshow-controls">
                        <button class="play-pause" onclick="togglePlayPause()">
                            <i class="fa fa-pause"></i>
                        </button>
                    </div>
                </div>
            </section>

            <div class="citation add-top-padding">
                <h1 id="citation">Citation</h1>
                <p> If you use this work or find it helpful, please consider citing: </p>
                <pre id="codecell0">Coming Soon</pre>
            </div>
        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p class="credit">Credit: The design of this project page is inspired by previous academic project pages, such as <a href="https://llm-grounded-diffusion.github.io/" target="_blank">LLM-grounded Diffusion</a>, <a href="https://describe-anything.github.io/" target="_blank">Describe Anything</a>.</p>
        </div>
    </footer>

    <script>
    function toggleMute(element) {
        const video = element.parentElement.querySelector('video');
        const icon = element.querySelector('i');
        const text = element.querySelector('.unmute-text');

        if (video.muted) {
            video.muted = false;
            icon.className = 'fa fa-volume-up';
            text.textContent = 'Mute';
        } else {
            video.muted = true;
            icon.className = 'fa fa-volume-off';
            text.textContent = 'Click to unmute';
        }
    }

    document.addEventListener('DOMContentLoaded', function() {
        const videos = document.querySelectorAll('video');
        videos.forEach(video => {
            video.addEventListener('play', function() {
                const overlay = this.parentElement.querySelector('.unmute-overlay');
                if (overlay) overlay.style.opacity = '0.8';
            });
            video.addEventListener('pause', function() {
                const overlay = this.parentElement.querySelector('.unmute-overlay');
                if (overlay) overlay.style.opacity = '0.8';
            });
        });

        // Initialize all slideshows
        document.querySelectorAll('.slideshow-container').forEach(container => {
            const slideshow = container.querySelector('.slideshow');
            const slides = slideshow.querySelectorAll('.slide');
            const prevButton = container.querySelector('.slideshow-nav.prev');
            const nextButton = container.querySelector('.slideshow-nav.next');
            const playPauseButton = container.querySelector('.play-pause');

            let currentSlide = 0;
            let autoplayInterval;
            let isPlaying = true;

            function showSlide(n) {
                slides.forEach(slide => slide.classList.remove('active'));
                currentSlide = (n + slides.length) % slides.length;
                slides[currentSlide].classList.add('active');
            }

            function changeSlide(n) {
                showSlide(currentSlide + n);
                resetAutoplay();
            }

            function togglePlayPause() {
                if (isPlaying) {
                    clearInterval(autoplayInterval);
                    playPauseButton.innerHTML = '<i class="fa fa-play"></i>';
                } else {
                    startAutoplay();
                    playPauseButton.innerHTML = '<i class="fa fa-pause"></i>';
                }
                isPlaying = !isPlaying;
            }

            function startAutoplay() {
                autoplayInterval = setInterval(() => {
                    showSlide(currentSlide + 1);
                }, 5000);
            }

            function resetAutoplay() {
                clearInterval(autoplayInterval);
                if (isPlaying) startAutoplay();
            }

            showSlide(0);
            startAutoplay();

            prevButton.addEventListener('click', () => changeSlide(-1));
            nextButton.addEventListener('click', () => changeSlide(1));
            playPauseButton.addEventListener('click', togglePlayPause);
        });

        // Handle main video play button
        const mainVideo = document.querySelector('.main-video');
        const playButton = document.querySelector('.play-button-overlay');

        if (mainVideo && playButton) {
            playButton.addEventListener('click', () => {
                mainVideo.play();
                mainVideo.classList.add('playing');
            });
            mainVideo.addEventListener('play', () => mainVideo.classList.add('playing'));
            mainVideo.addEventListener('pause', () => mainVideo.classList.remove('playing'));
            mainVideo.addEventListener('ended', () => mainVideo.classList.remove('playing'));
        }

        // ========================================
        // Scroll-based navigation highlight
        // ========================================
        const navLinks = document.querySelectorAll('.nav-links a');
        const sectionData = [];

        navLinks.forEach(link => {
            const targetId = link.getAttribute('href').substring(1);
            const section = document.getElementById(targetId);
            if (section) {
                sectionData.push({ id: targetId, el: section, link: link });
            }
        });

        const header = document.querySelector('.site-header');
        let currentActiveId = null;

        function updateActiveNav() {
            const headerHeight = header.offsetHeight;
            let bestMatch = null;
            let bestDist = Infinity;

            for (const s of sectionData) {
                const rect = s.el.getBoundingClientRect();
                // Section is considered "in view" if its top is above 60% viewport
                // and its bottom is below the header
                if (rect.top < window.innerHeight * 0.6 && rect.bottom > headerHeight) {
                    const dist = Math.abs(rect.top - headerHeight);
                    if (dist < bestDist) {
                        bestDist = dist;
                        bestMatch = s;
                    }
                }
            }

            if (bestMatch && currentActiveId !== bestMatch.id) {
                navLinks.forEach(l => l.classList.remove('active'));
                bestMatch.link.classList.add('active');
                currentActiveId = bestMatch.id;
            }
        }

        window.addEventListener('scroll', updateActiveNav, { passive: true });
        updateActiveNav(); // initial check
    });
    </script>
</body>
</html>
